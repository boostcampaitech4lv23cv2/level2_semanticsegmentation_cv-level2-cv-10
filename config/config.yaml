train:
<<<<<<< HEAD
  experiment_name: "densecrf-trainonly"
  train_path: '/train.json'
  val_path: '/val.json'
  batch_size: 8 # "input batch size for training"
  criterion: ce_dice_focal # "criterion type"
  epochs: 50 # "number of epochs to train"
=======
  experiment_name: "DeepLabV3+eff_b0"
  train_path: '/train.json'
  val_path: '/val.json'
  batch_size: 8 # "input batch size for training"
  criterion: focal # "criterion type"
  epochs: 100 # "number of epochs to train"
>>>>>>> master
  log_interval: 25 # "how many batches to wait before logging training status"
  grad_accum: 1 # "grad_accumulation"
  lr: 0.0001 # "learning rate"
  encoder: "efficientnet-b0"  # "encoder name"
  encoder_weights: "imagenet" # "pretrained weights"
  decoder: DeepLabV3 # "decoder name"
  optimizer: "AdamP" 
  seed: 42 # "random seed"
  valid_batch_size: 8 # "input batch size for validing"
  patience: 10 # early stopping patience
  scheduler: false
  copyblob: True
  cutmix: True
  project: "semantic_seg"
  entity: "cv10"
test:
  batch_size: 8 # "input batch size for validing"
  encoder: "efficientnet-b0"  # "encoder name"
  encoder_weights: "imagenet" # "pretrained weights"
  decoder: DeepLabV3 # "decoder name"
  output_dir: /opt/ml/input/cv_10/output