{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Uniform Soup]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PAN' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39m################ save dir path 적기 ################\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m[Uniform Soup]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m uniform_model, checkpoint \u001b[39m=\u001b[39m uniform_soup(args, checkpoint_paths, device \u001b[39m=\u001b[39;49m device)\n\u001b[1;32m     71\u001b[0m uniform_dict \u001b[39m=\u001b[39m uniform_model\u001b[39m.\u001b[39mstate_dict()\n\u001b[1;32m     73\u001b[0m torch\u001b[39m.\u001b[39msave(uniform_dict, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_dir_path, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 42\u001b[0m, in \u001b[0;36muniform_soup\u001b[0;34m(args, checkpoint_paths, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m     checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m./saved2\u001b[39m\u001b[39m'\u001b[39m, checkpoint_path), map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     41\u001b[0m     weight_dict \u001b[39m=\u001b[39m checkpoint\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m weight_dict\u001b[39m.\u001b[39;49mitems():\n\u001b[1;32m     43\u001b[0m         soups[k]\u001b[39m.\u001b[39mappend(v)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(soups):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PAN' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-10/\")\n",
    "\n",
    "# infer lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "\n",
    "def uniform_soup(args, checkpoint_paths, device = \"cpu\"):\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    model_module = getattr(smp, args.decoder)\n",
    "    model = model_module(\n",
    "        encoder_name=args.encoder,\n",
    "        encoder_weights=args.encoder_weights,     \n",
    "        in_channels=3,               \n",
    "        classes=11,  \n",
    "        encoder_output_stride=32                   \n",
    "    )\n",
    "    model.to(device)\n",
    "    \n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    checkpoint = {}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        checkpoint = torch.load(os.path.join('./saved2', checkpoint_path), map_location='cpu')\n",
    "        weight_dict = checkpoint\n",
    "        for k, v in weight_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "\n",
    "################ model cfg path 적기 ################\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "CONFIG_FILE_NAME = \"./config/config.yaml\"\n",
    "with open(CONFIG_FILE_NAME, \"r\") as yml_config_file:\n",
    "    args = yaml.load(yml_config_file, Loader=yaml.FullLoader)\n",
    "    args = EasyDict(args[\"train\"])\n",
    "\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "checkpoint_paths = os.listdir('/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-10/saved2')\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "device = \"cpu\"\n",
    "\n",
    "################ save dir path 적기 ################\n",
    "save_dir_path = '/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-10/saved2/'\n",
    "name = 'soup'\n",
    "################ save dir path 적기 ################\n",
    "\n",
    "print(\"\\n[Uniform Soup]\")\n",
    "uniform_model, checkpoint = uniform_soup(args, checkpoint_paths, device = device)\n",
    "uniform_dict = uniform_model.state_dict()\n",
    "\n",
    "torch.save(uniform_dict, os.path.join(save_dir_path, f'{name}.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 모델 & checkpoint 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ model cfg path 적기 ################\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "CONFIG_FILE_NAME = \"./config/config.yaml\"\n",
    "with open(CONFIG_FILE_NAME, \"r\") as yml_config_file:\n",
    "    args = yaml.load(yml_config_file, Loader=yaml.FullLoader)\n",
    "    args = EasyDict(args[\"train\"])\n",
    "\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "checkpoint_paths = os.listdir('./saved2')\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. uniform soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "model_module = getattr(smp, args.decoder)\n",
    "model = model_module(\n",
    "        encoder_name=args.encoder,\n",
    "        encoder_weights=args.encoder_weights,     \n",
    "        in_channels=3,               \n",
    "        classes=11,  \n",
    "        encoder_output_stride=32                   \n",
    "    )\n",
    "model.to(device)\n",
    "    \n",
    "model_dict = model.state_dict()\n",
    "soups = {key:[] for key in model_dict}\n",
    "checkpoint = {}\n",
    "checkpoint = torch.load(os.path.join('./saved_2', checkpoint_paths[0]), map_location='cpu')\n",
    "checkpoint2 = torch.load(os.path.join('./saved_2', 'soup.pth'), map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n",
      "457\n"
     ]
    }
   ],
   "source": [
    "print(len(checkpoint.keys()))\n",
    "print(len(checkpoint2.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(checkpoint2.keys()) - set(checkpoint.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n"
     ]
    }
   ],
   "source": [
    "print(len(set(checkpoint2.keys()) & set(checkpoint.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join('/opt/ml/input/cv_10/saved_2', 'soup.pth'), map_location='cuda')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 되는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.65s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Start validation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [00:20<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation || Average Loss: 0.5695 || macro : 0.2834 || micro: 0.7398\n",
      "IoU by class : {'Background': 0.8254, 'General trash': 0.4862, 'Paper': 0.6976, 'Paper pack': 0.0003, 'Metal': 0.0, 'Glass': 0.1862, 'Plastic': 0.001, 'Styrofoam': 0.2922, 'Plastic bag': 0.6286, 'Battery': 0.0, 'Clothing': 0.0}\n",
      "0.2834179401397705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from dataloaders.DataLoader import CustomDataLoader\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "dataset_path = '/opt/ml/input/data'\n",
    "val_path = dataset_path + '/kfold/val_fold2.json'\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                          ])\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, dataset_path=dataset_path, mode='val', transform=val_transform)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset, \n",
    "                            batch_size=8,\n",
    "                            shuffle=False,\n",
    "                            num_workers=4,\n",
    "                            collate_fn=collate_fn,\n",
    "                            drop_last=True)\n",
    "\n",
    "criterion1 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def validation(model, data_loader, device, criterion):\n",
    "    print(f'Start validation!')\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n_class = 11\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        \n",
    "        # metric의 묶음을 한 번에 사용\n",
    "        metric_collection = MetricCollection({\n",
    "            \"micro\": MulticlassJaccardIndex(num_classes=n_class, average=\"micro\"),\n",
    "            \"macro\": MulticlassJaccardIndex(num_classes=n_class, average=\"macro\"),      # mIoU\n",
    "            \"classwise\": MulticlassJaccardIndex(num_classes=n_class, average=\"none\")    # classwise IoU\n",
    "        })\n",
    "        metric_collection.cuda()\n",
    "\n",
    "        for step, (images, masks, _) in enumerate(tqdm(data_loader)):\n",
    "            \n",
    "            images = torch.stack(images)       \n",
    "            masks = torch.stack(masks).long()  \n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)            \n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1\n",
    "            \n",
    "            metric_collection.update(outputs, masks)\n",
    "        \n",
    "        result = metric_collection.compute()\n",
    "        micro = result[\"micro\"].item()\n",
    "        macro = result[\"macro\"].item()\n",
    "        classwise_results = result[\"classwise\"].detach().cpu().numpy()\n",
    "        category_list = ['Background', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
    "                'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "        IoU_by_class = {classes : round(IoU, 4) for IoU, classes in zip(classwise_results, category_list)}\n",
    "\n",
    "        avrg_loss = total_loss / cnt\n",
    "        print(f'Validation || Average Loss: {round(avrg_loss.item(), 4)} || macro : {round(macro, 4)} || micro: {round(micro, 4)}')\n",
    "        print(f'IoU by class : {IoU_by_class}')\n",
    "        \n",
    "    return avrg_loss, macro, IoU_by_class\n",
    "\n",
    "avrg_loss, val_mIoU, IoU_by_class = validation(model, val_loader, device, criterion1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
